{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find compound words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import splitter\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mi', 't']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.split('mit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/bilals01/Documents/NLP/project/quasi-rnn-run-12-09/evaluation/test_source.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    source = []\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        \n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            source.append(word)\n",
    "        \n",
    "  \n",
    "    \n",
    "with open(\"/Users/bilals01/Documents/NLP/project/quasi-rnn-run-12-09/evaluation/test_target.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    targets = []\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        \n",
    "        line = line.split('<JOIN>')\n",
    "        targets.append(line[0])\n",
    "        \n",
    "        \n",
    "    \n",
    "with open(\"/Users/bilals01/Documents/NLP/project/quasi-rnn-run-12-09/evaluation/test_pred.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    predictions = []\n",
    "    s2=[]\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        s1=(line.split('  '))\n",
    "        #print(s1)\n",
    "        for k, word in enumerate(s1):\n",
    "            s2.append(\" \".join([\"\".join(w.split(\" \")) for w in word.split(\"  \")]))\n",
    "        predictions.append(\" \".join(s2))\n",
    "        s2=[]\n",
    "        \n",
    "        \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get rid of /n \n",
    "source_u=[]\n",
    "for word in source: \n",
    "    source_u.append(word.replace(\".\",\"\"))\n",
    "    \n",
    "target_u=[]\n",
    "for i, t in enumerate(targets):\n",
    "    target_u.append(t.strip())\n",
    "    \n",
    "pred_u=[]\n",
    "for i, p in enumerate(predictions):\n",
    "    pred_u.append(p.strip())   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155032/155032 [00:23<00:00, 6517.38it/s]\n"
     ]
    }
   ],
   "source": [
    "compounds=[]\n",
    "\n",
    "for word in tqdm(source_u): \n",
    "    if len(splitter.split(word,'de_de'))>1 :\n",
    "        compounds.append(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2197\n"
     ]
    }
   ],
   "source": [
    "print(len(compounds))\n",
    "#compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the list of compounds in a file\n",
    "thefile = open('compounds.txt', 'w')\n",
    "\n",
    "for item in compounds:\n",
    "  thefile.write(\"%s\\n\" % item) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find and print sentence pairs where compoun words occur \n",
    "\n",
    "#experiment-1: find the sentences where the compound words occurs and  \n",
    "\n",
    "pred_comp=[]\n",
    "target_comp=[]\n",
    "source_comp=[]\n",
    "s=[]\n",
    "c=[]\n",
    "\n",
    "for i in range(len(pred_u)): \n",
    "    s.append(i)\n",
    "    for w in source_u[i].split():\n",
    "        if w in compounds: \n",
    "            c.append(i)\n",
    "            pred_comp.append(pred_u[i])\n",
    "            target_comp.append(target_u[i])\n",
    "            source_comp.append(source_u[i])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('pred_comp.txt', 'w')\n",
    "for item in pred_comp:\n",
    "  f1.write(\"%s\\n\" % item) \n",
    "\n",
    "f2 = open('target_comp.txt', 'w')\n",
    "for item in target_comp:\n",
    "  f2.write(\"%s\\n\" % item)\n",
    "    \n",
    "f3 = open('source_comp.txt', 'w')\n",
    "for item in target_comp:\n",
    "  f3.write(\"%s\\n\" % item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
