{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovered Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training targets\n",
    "        \n",
    "with open(\"/Users/carolineroper/Documents/School/Natural Language Processing/quasi-rnn-original/train_target_seqs.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    train_targets = []\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        \n",
    "        line = line.split('<JOIN>')\n",
    "        train_targets.append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#targets\n",
    "\n",
    "with open(\"/Users/carolineroper/Documents/School/Natural Language Processing/quasi-rnn-original/test_target_seqs.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    targets = []\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        \n",
    "        line = line.split('<JOIN>')\n",
    "        targets.append(line[0])\n",
    "        \n",
    "#predictions        \n",
    "    \n",
    "with open(\"/Users/carolineroper/Documents/School/NLP_Character_NMT/quasi-rnn/test_final_outputs.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    predictions = []\n",
    "    s2=[]\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        s1=(line.split('  '))\n",
    "        #print(s1)\n",
    "        for k, word in enumerate(s1):\n",
    "            s2.append(\" \".join([\"\".join(w.split(\" \")) for w in word.split(\"  \")]))\n",
    "        predictions.append(\" \".join(s2))\n",
    "        s2=[]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#source      \n",
    "    \n",
    "with open(\"/Users/carolineroper/Documents/School/Natural Language Processing/ge/test_source_seqs.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    \n",
    "    source = []\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        \n",
    "        line = line.split('<JOIN>')\n",
    "        source.append(line[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9773"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If I tell you that somebody ranked their life eight on a scale of ten, you have a lot of uncertainty about how happy they are with their experiencing self.\n",
      " If I tell you that somebody has his life as eight scales as a scale of death has arranged about how happy he is seeing with his experience of self.\n",
      "\n",
      "There's no hospital that can say \"No.\"\n",
      " There's no hospital.\n",
      "\n",
      "We live in a beautiful world really . a world in which one point six billion people live without electricity .\n",
      " We live in a beautiful world in a world where one command six million people live without else living without else living without else.\n",
      "\n",
      "They talk about it, they figure out what it's going to look like, they jockey for power.\n",
      " They talk about this, they think of how it will look at them at all.\n",
      "\n",
      "Just like we don't know when we are going to die .\n",
      " We also don't know when we die.\n",
      "\n",
      "You have to forget about your family .\n",
      " You put the family behind the family behind the way.\n",
      "\n",
      "Now I'm an optimist, so I sort of think it's probably going to do something like that.\n",
      " Now, I'm optimistic, so I'm going to think of something like this thing happening here.\n",
      "\n",
      "The mayor personally hands them out to the leaders of the delegations .\n",
      " This is going to be a personal framework on the delegation of mayor overall the delegation.\n",
      "\n",
      "But he's looking for things that his wife is doing without noticing, unintentional behaviors.\n",
      " Instead, he looks for things that he was to remain things that his wife, so in indiction, invade behavior.\n",
      "\n",
      "Madam ?\n",
      " Madam?\n",
      "\n",
      "And if you think about \"Avatar,\" if you think of why people were so touched by it -- never mind the Pocahontas story -- why so touched by the imagery?\n",
      " If you think about \"Avatar\" when you think about the people so that was so touched by the power of the power -- the power of the pocach story were they touched by the picture two?\n",
      "\n",
      "And when you suggest these are the things that will ensure the future of good food, someone, somewhere stands up and says, \"Hey guy, I love pink flamingos, but how are you going to feed the world?\"\n",
      " And if you can say that things are the things that the future was assured by the food food and say, \"Hey people, I love the peak, but how do you feed the world?\"\n",
      "\n",
      "With all that 's happening on the Internet .\n",
      " What happens to be at the Internet as well.\n",
      "\n",
      "I even wrote to the school principal and the host of a radio show.\n",
      " I even wrote the director and the moderator of a radio shooting radio shooting at the moderator.\n",
      "\n",
      "And that has a profound importance .\n",
      " And that has a deep sense.\n",
      "\n",
      "So now what I'm going to do is I'm going to vary the order in which these decisions appear.\n",
      " What I'm doing is I do is I change the sequels in the decisions.\n",
      "\n",
      "I've got something to show you.\n",
      " I've got some of the things I showed you this.\n",
      "\n",
      "I would aim to have more trust in the trustworthy but not in the untrustworthy.\n",
      " I would try to trust more trust to trust the trust but they don't do that.\n",
      "\n",
      "He started a landscaping and design floral company.\n",
      " He started a landscape gardener with flowers.\n",
      "\n",
      "With all the modern things we have , the smartphones and iPads and whatever .\n",
      " And in all these modern things, we have these modern things that we have, with smartphones and iPads and whatever.\n",
      "\n",
      "That's a topic for a different day.\n",
      " But that's a topic of another thing.\n",
      "\n",
      "So, this is World Without Oil.\n",
      " This is \"World without oil.\"\n",
      "\n",
      "That I was lucky .\n",
      " I had lucky.\n",
      "\n",
      "Something really weird is going on here.\n",
      " Something very strangely happening here.\n",
      "\n",
      "The second thing I learned that day -- and this is as we clear the George Washington Bridge, which was by not a lot -- I thought about, wow, I really feel one real regret.\n",
      " The second thing I learned about this day -- and that was when we made the George Washington bridge, so pretty much about hair -- there I thought people that I really released this thing that I really released.\n",
      "\n",
      "Even though neither one of these things has any pharmaceutical -- they're sugar pills.\n",
      " And that, although not any pharmaceutical -- it's just suggesting sugar pills -- it's just suggesting sugar pills.\n",
      "\n",
      "Thinking about death clarifies your life.\n",
      " The idea of the death is most like us that life works.\n",
      "\n",
      "I would go to university in the mornings and be greeted by , hey Achmed , what kind of bullshit are your sheiks up to ?\n",
      " I mean, the morning went to the U.K., and I was greeted here, hey achieved the Achedulation of your face of a filling shit for a fish.\n",
      "\n",
      "Because autistic or not, the differences that we have -- We've got a gift! Everyone's got a gift inside of us, and in all honesty, the pursuit of normality is the ultimate sacrifice of potential.\n",
      " Because, autisticly or not, the differences we have -- we have a gift; everybody has a gift in there and all of us all honesty that is ultimate victims of potential.\n",
      "\n",
      "And finally, this older black man with this very worried look on his face came into the courtroom and sat down behind me, almost at counsel table.\n",
      " Finally, this older black man came to a very worried face in the courtyard and sat down to me almost the defendant bank.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "randoms = random.sample(range(0,len(targets)), 30)\n",
    "\n",
    "for i in randoms:\n",
    "    print (targets[i], predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Vocabulary of Training Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s) #separates punctuation from the word\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s) #strips anything that isn't a character of punctuation\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_vocabulary(seq, vocab_size):\n",
    "    counter = Counter()\n",
    "    for sentence in seq:\n",
    "        counter.update(normalizeString(sentence).split())\n",
    "    vocabulary = [count[0] for count in counter.most_common(vocab_size)]\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vocab = find_vocabulary(train_targets, 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49545"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_vocab = find_vocabulary(predictions, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8944"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get \"Discovered\" Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oov = []\n",
    "\n",
    "for word in result_vocab:\n",
    "    if word not in train_vocab:\n",
    "        oov.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_example(word):\n",
    "    for i in range(len(predictions)):\n",
    "        if word in normalizeString(predictions[i]).split():\n",
    "            index_where_found = i\n",
    "    if word in normalizeString(targets[index_where_found]).split():\n",
    "        correctness = True\n",
    "    else:\n",
    "        correctness= False\n",
    "    return word, targets[index_where_found], predictions[index_where_found], correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Find Correct \"Discovered Words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06401384083044982"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "111/1734"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1734"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct = 0\n",
    "correct_discoveries = []\n",
    "disc_targets = []\n",
    "disc_predictions = []\n",
    "\n",
    "for word in oov:\n",
    "    word, target, prediction, correctness = find_example(word)\n",
    "    if correctness == True:\n",
    "        num_correct += 1\n",
    "        correct_discoveries.append(word)\n",
    "        disc_targets.append(target)\n",
    "        disc_predictions.append(prediction)\n",
    "        \n",
    "num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aed',\n",
       " 'femto',\n",
       " 'ripley',\n",
       " 'catholics',\n",
       " 'elaborative',\n",
       " 'simonides',\n",
       " 'kea',\n",
       " 'ticketing',\n",
       " 'androgen',\n",
       " 'fou']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_discoveries[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_example_with_source(word):\n",
    "    for i in range(len(predictions)):\n",
    "        if word in normalizeString(predictions[i]).split():\n",
    "            index_where_found = i\n",
    "    if word in normalizeString(targets[index_where_found]).split():\n",
    "        correctness = True\n",
    "    else:\n",
    "        correctness= False\n",
    "    return word, source[index_where_found], targets[index_where_found], predictions[index_where_found], correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('zaragoza',\n",
       " 'Alle Kinder aus Zaragoza kamen zu dem Gebaude, denn die Art wie sie mit dem Gebaude spielten war ganz anders.\\n',\n",
       " 'All the kids from Zaragoza came to the building, because the way of engaging with the building became something different.\\n',\n",
       " 'All kids came from zaragoza to the building, because the way they played with the building was actually different.\\n',\n",
       " True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_example_with_source('zaragoza')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find examples of Incorrect \"Discovered Words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paddogic',\n",
       " 'sequels',\n",
       " 'mogadicho',\n",
       " 'suspensions',\n",
       " 'maastrict',\n",
       " 'baes',\n",
       " 'tiangular',\n",
       " 'progravation',\n",
       " 'apolog',\n",
       " 'beehoven']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_oov[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incorrect_oov = list(set(oov).difference(set(correct_discoveries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thefile = open('incorrect_new_words.txt', 'w', encoding = 'utf-8')\n",
    "\n",
    "randoms = random.sample(range(0,len(incorrect_oov)), 10)\n",
    "\n",
    "for i in randoms:\n",
    "    output = list(find_example(incorrect_oov[i]))\n",
    "    #output = [str(x) for x in output]\n",
    "    thefile.write(\"\\n\")\n",
    "    for x in output[0:3]:\n",
    "        thefile.write(\"\\n%s\" % x)\n",
    "thefile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
